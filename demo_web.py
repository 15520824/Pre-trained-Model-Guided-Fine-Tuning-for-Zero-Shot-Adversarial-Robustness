import streamlit as st
import torch
import clip
from PIL import Image
import numpy as np
import cv2
import torch.nn.functional as F
import io
import os
from collections import OrderedDict

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="üõ°Ô∏è Zero-Shot Robustness Lab", layout="wide")

# --- CLASS GRADCAM ---
class ClipGradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        self.target_layer.register_forward_hook(self.save_activation)
        self.target_layer.register_full_backward_hook(self.save_gradient)

    def save_activation(self, module, input, output): self.activations = output
    def save_gradient(self, module, grad_input, grad_output): self.gradients = grad_output[0]

    def __call__(self, image_input, text_features, device, dummy_prompt):
        self.model.zero_grad()
        img_emb = self.model.encode_image(image_input.float(), dummy_prompt)
        img_norm = img_emb / img_emb.norm(dim=-1, keepdim=True)
        score = (img_norm * text_features).sum()
        score.backward(retain_graph=True)
        
        if self.gradients is None: return np.zeros((7, 7))
        weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)
        cam = F.relu(torch.sum(weights * self.activations, dim=1, keepdim=True))
        return cam.squeeze().cpu().detach().numpy()

# --- H√ÄM T·∫†O NHI·ªÑU FGSM ---
def create_attack(model, image, text_features, epsilon, device, dummy_prompt):
    if epsilon == 0: return image.clone().detach()
    
    img_adv = image.clone().detach().requires_grad_(True).float()
    img_emb = model.encode_image(img_adv, dummy_prompt)
    img_norm = img_emb / img_emb.norm(dim=-1, keepdim=True)
    
    loss = (img_norm * text_features).sum()
    model.zero_grad()
    loss.backward()
    
    with torch.no_grad():
        img_adv = img_adv + epsilon * img_adv.grad.sign()
        img_adv = torch.clamp(img_adv, -1, 1)
    return img_adv.detach()

# --- D·ª∞ ƒêO√ÅN ZERO-SHOT ---
def predict_zero_shot(model, image_tensor, text_features, dummy_prompt):
    with torch.no_grad():
        img_emb = model.encode_image(image_tensor.float(), dummy_prompt)
        img_norm = img_emb / img_emb.norm(dim=-1, keepdim=True)
        logits = (100.0 * img_norm @ text_features.T).softmax(dim=-1)
        conf, idx = logits[0].max(0)
    return conf, idx

# --- H√ÄM TR·ªòN HEATMAP ---
def overlay_heatmap(img_pil, mask):
    mask = (mask - mask.min()) / (mask.max() - mask.min() + 1e-8)
    img_resized = np.array(img_pil.resize((224, 224)))
    heatmap = cv2.applyColorMap(np.uint8(255 * cv2.resize(mask, (224, 224))), cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB) # Chuy·ªÉn BGR c·ªßa OpenCV sang RGB
    return np.uint8(heatmap * 0.4 + img_resized * 0.6)

# --- LOAD MODELS ---
@st.cache_resource
def load_all_models(ckpt_path=None):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model_orig, preprocess = clip.load("RN50", device=device, jit=False)
    model_orig = model_orig.float().eval()
    
    model_robust, _ = clip.load("RN50", device=device, jit=False)
    model_robust = model_robust.float().eval()
    
    if ckpt_path and os.path.exists(ckpt_path):
        try:
            checkpoint = torch.load(ckpt_path, map_location=device)
            state_dict = checkpoint.get('state_dict', checkpoint) if isinstance(checkpoint, dict) else checkpoint
            new_state_dict = OrderedDict()
            for k, v in state_dict.items():
                new_state_dict[k.replace('module.', '')] = v
            model_robust.load_state_dict(new_state_dict, strict=False)
            st.sidebar.success("‚úÖ ƒê√£ n·∫°p checkpoint th√†nh c√¥ng!")
        except Exception as e:
            st.sidebar.warning(f"‚ö†Ô∏è L·ªói n·∫°p file: {e}")
    return model_orig, model_robust, preprocess, device

# --- GIAO DI·ªÜN ---
st.title("üõ°Ô∏è Zero-Shot Adversarial Robustness Lab")

with st.sidebar:
    st.header("C·∫•u h√¨nh")
    ckpt_path = st.text_input("ƒê∆∞·ªùng d·∫´n file .pth/.tar", "checkpoint.pth.tar")
    epsilon = st.slider("C∆∞·ªùng ƒë·ªô nhi·ªÖu (Epsilon)", 0.0, 0.1, 0.0, step=0.01)

model_orig, model_robust, preprocess, device = load_all_models(ckpt_path)

col_up1, col_up2 = st.columns([1, 2])
with col_up1:
    uploaded_file = st.file_uploader("Upload ·∫£nh", type=["jpg", "png", "jpeg"])
with col_up2:
    labels_input = st.text_input("Nh√£n ph√¢n lo·∫°i", value="dog, cat, car, tree")

if uploaded_file:
    img_pil = Image.open(uploaded_file).convert("RGB")
    labels = [l.strip() for l in labels_input.split(',')]
    text_tokens = clip.tokenize(labels).to(device)
    dummy_prompt = torch.tensor([0]).to(device)

    # Tr√≠ch xu·∫•t & Chu·∫©n h√≥a text features
    with torch.no_grad():
        text_f_orig = model_orig.encode_text(text_tokens).float()
        text_f_orig /= text_f_orig.norm(dim=-1, keepdim=True)
        
        text_f_robust = model_robust.encode_text(text_tokens).float()
        text_f_robust /= text_f_robust.norm(dim=-1, keepdim=True)

        img_clean_tensor = preprocess(img_pil).unsqueeze(0).to(device).float()

    # 1. D·ª± ƒëo√°n ·∫£nh s·∫°ch
    c_conf, c_idx = predict_zero_shot(model_orig, img_clean_tensor, text_f_orig, dummy_prompt)
    clean_label = labels[c_idx.item()]

    # 2. T·∫°o ·∫£nh nhi·ªÖu & Grad-CAM
    with torch.enable_grad():
        img_adv_tensor = create_attack(model_orig, img_clean_tensor, text_f_orig[c_idx : c_idx+1], epsilon, device, dummy_prompt)
        
        cam_orig_obj = ClipGradCAM(model_orig, model_orig.visual.layer4)
        cam_robust_obj = ClipGradCAM(model_robust, model_robust.visual.layer4)

        mask_clean = cam_orig_obj(img_clean_tensor.clone().requires_grad_(True), text_f_orig[c_idx : c_idx+1], device, dummy_prompt)
        mask_adv_orig = cam_orig_obj(img_adv_tensor.clone().requires_grad_(True), text_f_orig[c_idx : c_idx+1], device, dummy_prompt)
        mask_adv_robust = cam_robust_obj(img_adv_tensor.clone().requires_grad_(True), text_f_robust[c_idx : c_idx+1], device, dummy_prompt)

    # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
    st.header("üìä Ph√¢n t√≠ch chi ti·∫øt")
    
    # H√†ng 1: Clean
    st.subheader("1. Ph√¢n t√≠ch ·∫£nh G·ªëc (Clean)")
    col1, col2 = st.columns(2)
    with col1:
        st.image(img_pil.resize((224,224)), caption="·∫¢nh s·∫°ch", width=350)
        st.metric("D·ª± ƒëo√°n g·ªëc", clean_label, f"{c_conf.item()*100:.2f}%")
    with col2:
        st.image(overlay_heatmap(img_pil, mask_clean), caption="V√πng ch√∫ √Ω Clean", width=350)

    st.divider()

    # H√†ng 2: Adversarial
    st.subheader(f"2. ƒê·ªëi ph√≥ t·∫•n c√¥ng FGSM (Epsilon = {epsilon})")
    res1, res2 = st.columns(2)

    # Kh√¥i ph·ª•c ·∫£nh nhi·ªÖu t·ª´ Tensor sang PIL ƒë·ªÉ hi·ªÉn th·ªã v√† download
    # (·∫¢nh CLIP preprocess th∆∞·ªùng n·∫±m trong kho·∫£ng [-1, 1], c·∫ßn ƒë∆∞a v·ªÅ [0, 255])
    adv_np = img_adv_tensor.squeeze().cpu().numpy().transpose(1, 2, 0)
    # Denormalize (L∆∞u √Ω: ƒê√¢y l√† b∆∞·ªõc x·∫•p x·ªâ ƒë·ªÉ hi·ªÉn th·ªã, ·∫£nh g·ªëc trong Tensor v·∫´n chu·∫©n)
    adv_np = (adv_np - adv_np.min()) / (adv_np.max() - adv_np.min() + 1e-8)
    adv_pil = Image.fromarray((adv_np * 255).astype(np.uint8))

    with res1:
        st.error("‚ùå CLIP Nguy√™n b·∫£n")
        conf, idx = predict_zero_shot(model_orig, img_adv_tensor, text_f_orig, dummy_prompt)
        st.image(overlay_heatmap(adv_pil, mask_adv_orig), use_container_width=True)
        delta_status = "B·ªã t·∫•n c√¥ng" if idx != c_idx else "ƒê√∫ng"
        st.metric(label="D·ª± ƒëo√°n", value=labels[idx.item()], delta=delta_status, delta_color="inverse")
        st.caption(f"Tin c·∫≠y: {conf.item()*100:.2f}%")

    with res2:
        st.success("‚úÖ CLIP Robust")
        conf_r, idx_r = predict_zero_shot(model_robust, img_adv_tensor, text_f_robust, dummy_prompt)
        st.image(overlay_heatmap(adv_pil, mask_adv_robust), use_container_width=True)
        delta_status_r = "Gi·ªØ v·ªØng" if idx_r == c_idx else "B·ªã l·ª´a"
        st.metric(label="D·ª± ƒëo√°n", value=labels[idx_r.item()], delta=delta_status_r)
        st.caption(f"Tin c·∫≠y: {conf_r.item()*100:.2f}%")

    # --- N√öT DOWNLOAD ---
    st.divider()
    buf = io.BytesIO()
    adv_pil.save(buf, format="PNG")
    st.download_button(
        label="üì• T·∫£i ·∫£nh Adversarial (ƒë√£ th√™m nhi·ªÖu)",
        data=buf.getvalue(),
        file_name=f"adversarial_eps_{epsilon}.png",
        mime="image/png"
    )