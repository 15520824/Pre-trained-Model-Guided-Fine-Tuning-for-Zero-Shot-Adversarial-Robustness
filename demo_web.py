import streamlit as st
import torch
import clip
from PIL import Image
import pandas as pd
import numpy as np
import cv2
import torch.nn.functional as F

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="Zero-Shot Robustness Demo", layout="wide")

# --- CLASS GRADCAM T·ª∞ VI·∫æT ---
class ClipGradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None

        # ƒêƒÉng k√Ω hook
        target_layer.register_forward_hook(self.save_activation)
        target_layer.register_backward_hook(self.save_gradient)

    def save_activation(self, module, input, output):
        self.activations = output

    def save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]

    def __call__(self, image_input, text_features, device):
        # 1. Forward Image
        dummy_prompt = torch.tensor([0]).to(device)
        image_features = self.model.encode_image(image_input, dummy_prompt)
        
        # 2. T√≠nh Score
        image_features_norm = image_features / image_features.norm(dim=-1, keepdim=True)
        text_features_norm = text_features / text_features.norm(dim=-1, keepdim=True)
        score = (image_features_norm * text_features_norm).sum()
        
        # 3. Backward
        self.model.zero_grad()
        score.backward()
        
        # 4. T√≠nh CAM
        gradients = self.gradients
        activations = self.activations
        
        # Ki·ªÉm tra n·∫øu kh√¥ng b·∫Øt ƒë∆∞·ª£c gradient (tr√°nh l·ªói None)
        if gradients is None or activations is None:
            return np.zeros((7, 7), dtype=np.float32)

        weights = torch.mean(gradients, dim=(2, 3), keepdim=True)
        cam = torch.sum(weights * activations, dim=1, keepdim=True)
        cam = F.relu(cam)
        
        cam = cam.squeeze().cpu().detach().numpy()
        return cam

# --- H√ÄM X·ª¨ L√ù ·∫¢NH HEATMAP (ƒê√É FIX L·ªñI OPENCV) ---
def overlay_heatmap(img_pil, cam_mask):
    # 1. √âp ki·ªÉu sang float32 ngay l·∫≠p t·ª©c ƒë·ªÉ tr√°nh l·ªói OpenCV func != 0
    cam_mask = cam_mask.astype(np.float32)

    # 2. Chu·∫©n h√≥a mask v·ªÅ 0-1
    cam_mask = cam_mask - np.min(cam_mask)
    cam_mask = cam_mask / (np.max(cam_mask) + 1e-8)
    
    # 3. Chuy·ªÉn ·∫£nh g·ªëc sang Numpy
    img = np.array(img_pil)
    h, w = img.shape[:2]
    
    # 4. Resize mask (Gi·ªù ƒë√£ an to√†n v√¨ l√† float32)
    heatmap = cv2.resize(cam_mask, (w, h))
    
    # 5. T√¥ m√†u
    heatmap = np.uint8(255 * heatmap)
    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
    
    # 6. Tr·ªôn ·∫£nh
    # ƒê·∫£m b·∫£o ·∫£nh g·ªëc v√† heatmap c√πng k√≠ch th∆∞·ªõc v√† ki·ªÉu d·ªØ li·ªáu
    if len(img.shape) == 2: # N·∫øu l√† ·∫£nh ƒëen tr·∫Øng
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
        
    result = heatmap * 0.4 + img * 0.6
    return np.uint8(result)

# --- LOAD MODEL ---
@st.cache_resource
def load_clip_model():
    device = "cuda" if torch.cuda.is_available() else "cpu"
    # D√πng RN50 v√¨ ViT kh√¥ng c√≥ layer4 ƒë·ªÉ soi GradCAM
    model, preprocess = clip.load("RN50", device=device) 
    model.eval()
    return model, preprocess, device

with st.spinner("ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng..."):
    model, preprocess, device = load_clip_model()

# --- GIAO DI·ªÜN ---
st.title("üõ°Ô∏è Demo: Zero-Shot Adversarial Robustness")

col1, col2 = st.columns([1, 1.5])

with col1:
    st.header("1. Input")
    uploaded_file = st.file_uploader("Upload ·∫£nh", type=["jpg", "png", "jpeg"])
    labels_input = st.text_area("Nh√£n (c√°ch nhau d·∫•u ph·∫©y)", value="a dog, a cat, a car, a plane")
    show_heatmap = st.checkbox("Hi·ªÉn th·ªã Heatmap (Grad-CAM)", value=True)
    btn = st.button("Ph√¢n t√≠ch", type="primary")

with col2:
    st.header("2. K·∫øt qu·∫£")
    if uploaded_file and btn:
        img_pil = Image.open(uploaded_file).convert("RGB")
        
        # --- CLASSIFICATION ---
        img_tensor = preprocess(img_pil).unsqueeze(0).to(device)
        labels = [l.strip() for l in labels_input.split(',')]
        text = clip.tokenize(labels).to(device)
        
        with torch.no_grad():
            dummy = torch.tensor([0]).to(device)
            img_emb = model.encode_image(img_tensor, dummy)
            text_emb = model.encode_text(text)
            
            img_emb /= img_emb.norm(dim=-1, keepdim=True)
            text_emb /= text_emb.norm(dim=-1, keepdim=True)
            similarity = (100.0 * img_emb @ text_emb.T).softmax(dim=-1)
            values, indices = similarity[0].topk(len(labels))
            
        scores = values.cpu().numpy() * 100
        top_labels = [labels[idx] for idx in indices.cpu().numpy()]
        st.bar_chart(pd.DataFrame({"Label": top_labels, "Score": scores}).set_index("Label"))
        
        top_idx = indices[0].item()
        st.success(f"D·ª± ƒëo√°n: **{top_labels[0]}** ({scores[0]:.2f}%)")

        # --- HEATMAP ---
        if show_heatmap:
            with st.spinner("ƒêang v·∫Ω Heatmap..."):
                try:
                    with torch.enable_grad():
                        target_layer = model.visual.layer4
                        grad_cam = ClipGradCAM(model, target_layer)
                        
                        target_text_emb = text_emb[top_idx].unsqueeze(0)
                        
                        # Ch·∫°y GradCAM
                        mask = grad_cam(img_tensor, target_text_emb, device)
                        
                        # V·∫Ω ·∫£nh
                        heatmap_img = overlay_heatmap(img_pil, mask)
                        
                        st.image(heatmap_img, caption=f"AI ƒëang nh√¨n v√†o ƒë√¢u ƒë·ªÉ nh·∫≠n ra '{top_labels[0]}'?", use_container_width=True)
                except Exception as e:
                    st.error(f"L·ªói Heatmap: {e}")
                    import traceback
                    st.text(traceback.format_exc()) # In chi ti·∫øt l·ªói n·∫øu c√≤n

    elif uploaded_file:
        st.image(uploaded_file, caption="·∫¢nh g·ªëc", width=400)